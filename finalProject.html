<!-- Luisa Zorzetto - CTS 1000 -->

<!-- oedAssignment.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Final Project</title>
    <link rel="stylesheet" href="webstyle.css">
</head>
<body>

    <!-- Header -->
    <header>
        <h1>Luisa Zorzetto's Portfolio</h1>
        <!-- Navigation -->
        <nav>
            <a href="index.html">Portfolio Home</a>
            <a href="CTS1000.html">CTS*1000</a>
        </nav>
    </header>

    <!-- Main Content -->
    <main id="main-content">
        <section class="info">
            <br>
            <h1 style= "color: #854C4C;">Final Project Proposal</h1>
            <br>

            <div class="list-container-2">
                <b>Topic:</b> Gender bias in medicine 
                <br><b>Keyword:</b> Data, Code and Algorithms
                <br><b>Question:</b> What effects do gender biases have on the design and behaviours of technological medical systems?
                <br><b>Form:</b> Essay

                <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The relationship between culture and technology is evident throughout modern society. An area with a clear example of where this connection appears is in the creation of technologies. The information that powers our technology is a reflection of the people producing it. The topic of “gender bias in algorithms” is a broad topic, so looking into a specific field, the medical field, the scope of this assignment can be narrowed. Therefore, leading to the question, what effects do gender biases have on the design and behaviours of technological medical systems?
                <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Historically, medical data used to influence treatments or symptom detection was collected mostly from men. These datasets became commonly used and accepted as “typical” markers in patients. This led to men being prioritized in medicine, even before the use of AI and medical algorithms. In the medical field, societal assumptions, like these markers, are embedded into the data used to train and develop medical systems, leading to the same detection and treatment plans for both genders.  When studying data, code, and algorithms the topic of gender bias is one that requires further study and research. Gender biases in medical data are dangerous as they often lead to under-detected symptoms, misinterpreted data, or fewer effective procedures on women as the methodology is predominantly developed with male datasets. This topic is important since medical systems have a direct impact on our society’s health and well-being. To determine the reasoning for this bias, it is necessary to look at both technical and cultural factors, such as who is gathering the data, what is being collected, and what is deemed “standard”. To analyse this question, I will look at three components: how gender data gaps occur, how gender data gaps enter algorithms, and examples of medical technologies that are affected by gender bias. 
                <br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;The form of this project will be an essay as this is the most appropriate format to connect theories and examples of this argument. An essay format will allow for a structured explanation and the opportunity to connect the three components above. Through this form, the exploration of how gender data gaps in medicine have developed, and their consequences in healthcare, will be analyzed with evidence and research to link the cultural and technical relationships in society. 

            </div>

        </section>
    </main>

    <!-- Footer -->
        <footer>
            <p>Created by Luisa Zorzetto</p>
            <p>Email: lzorzett@uoguelph.ca</p>
        </footer>

</body>
</html>